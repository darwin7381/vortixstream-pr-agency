from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Query
from typing import List, Optional
from datetime import datetime
import logging
import mimetypes
from PIL import Image
import io

from ..core.database import db
from ..models.media import MediaFile, MediaFileCreate, MediaFileUpdate
from ..services.r2_storage import r2_storage

router = APIRouter(prefix="/media")
logger = logging.getLogger(__name__)


# æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
ALLOWED_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg'}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB


@router.post("/folders", status_code=201)
async def create_folder(folder_name: str = Form(...)):
    """
    å‰µå»ºæ–°è³‡æ–™å¤¾
    
    åœ¨ R2 ä¸­å‰µå»ºä¸€å€‹ .keep æª”æ¡ˆä½œç‚ºè³‡æ–™å¤¾ä½”ä½ç¬¦
    """
    try:
        # é©—è­‰è³‡æ–™å¤¾åç¨±
        if not folder_name or not folder_name.strip():
            raise HTTPException(status_code=400, detail="è³‡æ–™å¤¾åç¨±ä¸èƒ½ç‚ºç©º")
        
        folder_name = folder_name.strip()
        
        # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å·²å­˜åœ¨
        async with db.pool.acquire() as conn:
            existing = await conn.fetchval(
                "SELECT COUNT(*) FROM media_files WHERE folder = $1",
                folder_name
            )
        
        if existing > 0:
            raise HTTPException(status_code=400, detail=f"è³‡æ–™å¤¾ã€Œ{folder_name}ã€å·²å­˜åœ¨")
        
        # åœ¨ R2 å‰µå»º .keep æª”æ¡ˆï¼ˆä½”ä½ç¬¦ï¼‰
        keep_content = b"# This file is used to keep the folder in R2 storage"
        keep_key = f"{folder_name}/.keep"
        
        upload_result = r2_storage.upload_file(
            file_content=keep_content,
            filename=".keep",
            folder=folder_name,
            content_type="text/plain"
        )
        
        # å„²å­˜åˆ°è³‡æ–™åº«
        async with db.pool.acquire() as conn:
            row = await conn.fetchrow(
                """
                INSERT INTO media_files (
                    filename, original_filename, file_key, file_url,
                    file_size, mime_type, folder, alt_text, caption, uploaded_by
                )
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
                RETURNING *
                """,
                ".keep",
                ".keep",
                keep_key,
                upload_result['url'],
                upload_result['size'],
                "text/plain",
                folder_name,
                "Folder placeholder",
                "Auto-generated folder keeper",
                "system"
            )
        
        logger.info(f"âœ… Folder created: {folder_name}")
        return {
            "message": f"è³‡æ–™å¤¾ã€Œ{folder_name}ã€å·²å‰µå»º",
            "folder": folder_name,
            "keep_file": dict(row)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to create folder: {e}")
        raise HTTPException(status_code=500, detail=f"å‰µå»ºè³‡æ–™å¤¾å¤±æ•—ï¼š{str(e)}")


@router.post("/upload", response_model=MediaFile, status_code=201)
async def upload_media(
    file: UploadFile = File(...),
    folder: str = Form("uploads"),
    alt_text: Optional[str] = Form(None),
    caption: Optional[str] = Form(None),
):
    """
    ä¸Šå‚³åª’é«”æª”æ¡ˆåˆ° R2
    
    - æ”¯æ´æ ¼å¼ï¼šjpg, jpeg, png, gif, webp, svg
    - æœ€å¤§å¤§å°ï¼š10MB
    - è‡ªå‹•ç”Ÿæˆå”¯ä¸€æª”å
    - å„²å­˜åˆ°è³‡æ–™åº«
    """
    
    # æª¢æŸ¥æª”æ¡ˆå‰¯æª”å
    file_ext = f".{file.filename.rsplit('.', 1)[-1].lower()}" if '.' in file.filename else ''
    if file_ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚å…è¨±çš„æ ¼å¼ï¼š{', '.join(ALLOWED_EXTENSIONS)}"
        )
    
    # è®€å–æª”æ¡ˆå…§å®¹
    content = await file.read()
    file_size = len(content)
    
    # æª¢æŸ¥æª”æ¡ˆå¤§å°
    if file_size > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=400,
            detail=f"æª”æ¡ˆå¤ªå¤§ã€‚æœ€å¤§å…è¨±å¤§å°ï¼š{MAX_FILE_SIZE / 1024 / 1024}MB"
        )
    
    if file_size == 0:
        raise HTTPException(status_code=400, detail="æª”æ¡ˆæ˜¯ç©ºçš„")
    
    try:
        # ç²å–åœ–ç‰‡å°ºå¯¸
        width, height = None, None
        try:
            image = Image.open(io.BytesIO(content))
            width, height = image.size
            logger.info(f"ğŸ“ Image dimensions: {width} x {height}")
        except Exception as e:
            logger.warning(f"âš ï¸ Could not get image dimensions: {e}")
        
        # ä¸Šå‚³åˆ° R2
        upload_result = r2_storage.upload_file(
            file_content=content,
            filename=file.filename,
            folder=folder,
            content_type=file.content_type
        )
        
        # å„²å­˜è¨˜éŒ„åˆ°è³‡æ–™åº«ï¼ˆåŒ…å«å°ºå¯¸ï¼‰
        async with db.pool.acquire() as conn:
            row = await conn.fetchrow(
                """
                INSERT INTO media_files (
                    filename, original_filename, file_key, file_url,
                    file_size, mime_type, folder, alt_text, caption, uploaded_by,
                    width, height
                )
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
                RETURNING *
                """,
                upload_result['key'].split('/')[-1],  # filename
                upload_result['original_filename'],
                upload_result['key'],
                upload_result['url'],
                upload_result['size'],
                upload_result['content_type'],
                folder,
                alt_text,
                caption,
                "admin",
                width,
                height
            )
        
        logger.info(f"âœ… Media file uploaded and saved: {upload_result['key']}")
        return dict(row)
        
    except Exception as e:
        logger.error(f"âŒ Failed to upload media: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸Šå‚³å¤±æ•—ï¼š{str(e)}")


@router.get("/files", response_model=List[MediaFile])
async def get_media_files(
    folder: Optional[str] = Query(None),
    limit: int = Query(100, ge=1, le=500),
    search: Optional[str] = None
):
    """å–å¾—åª’é«”æª”æ¡ˆåˆ—è¡¨"""
    
    async with db.pool.acquire() as conn:
        # å»ºç«‹æŸ¥è©¢æ¢ä»¶
        conditions = []
        params = []
        param_count = 1
        
        if folder:
            conditions.append(f"folder = ${param_count}")
            params.append(folder)
            param_count += 1
        
        if search:
            conditions.append(f"(original_filename ILIKE ${param_count} OR alt_text ILIKE ${param_count})")
            params.append(f"%{search}%")
            param_count += 1
        
        where_clause = " AND ".join(conditions) if conditions else "TRUE"
        
        rows = await conn.fetch(
            f"""
            SELECT * FROM media_files
            WHERE {where_clause}
            ORDER BY created_at DESC
            LIMIT ${param_count}
            """,
            *params, limit
        )
    
    return [dict(row) for row in rows]


@router.get("/files/{file_id}", response_model=MediaFile)
async def get_media_file(file_id: int):
    """å–å¾—å–®å€‹åª’é«”æª”æ¡ˆè³‡è¨Š"""
    
    async with db.pool.acquire() as conn:
        row = await conn.fetchrow(
            "SELECT * FROM media_files WHERE id = $1",
            file_id
        )
    
    if not row:
        raise HTTPException(status_code=404, detail="Media file not found")
    
    return dict(row)


@router.patch("/files/{file_id}", response_model=MediaFile)
async def update_media_file(file_id: int, update: MediaFileUpdate):
    """æ›´æ–°åª’é«”æª”æ¡ˆè³‡è¨Šï¼ˆalt text, captionï¼‰"""
    
    update_data = update.model_dump(exclude_unset=True)
    
    if not update_data:
        raise HTTPException(status_code=400, detail="No fields to update")
    
    set_clauses = []
    params = []
    param_count = 1
    
    for field, value in update_data.items():
        set_clauses.append(f"{field} = ${param_count}")
        params.append(value)
        param_count += 1
    
    set_clauses.append(f"updated_at = ${param_count}")
    params.append(datetime.now())
    param_count += 1
    
    params.append(file_id)
    
    async with db.pool.acquire() as conn:
        row = await conn.fetchrow(
            f"""
            UPDATE media_files
            SET {', '.join(set_clauses)}
            WHERE id = ${param_count}
            RETURNING *
            """,
            *params
        )
    
    if not row:
        raise HTTPException(status_code=404, detail="Media file not found")
    
    return dict(row)


@router.delete("/files/{file_id}", status_code=204)
async def delete_media_file(file_id: int):
    """åˆªé™¤åª’é«”æª”æ¡ˆï¼ˆå¾ R2 å’Œè³‡æ–™åº«ï¼‰"""
    
    async with db.pool.acquire() as conn:
        # å…ˆç²å–æª”æ¡ˆè³‡è¨Š
        row = await conn.fetchrow(
            "SELECT file_key FROM media_files WHERE id = $1",
            file_id
        )
        
        if not row:
            raise HTTPException(status_code=404, detail="Media file not found")
        
        file_key = row['file_key']
        
        # å¾ R2 åˆªé™¤
        r2_storage.delete_file(file_key)
        
        # å¾è³‡æ–™åº«åˆªé™¤
        await conn.execute(
            "DELETE FROM media_files WHERE id = $1",
            file_id
        )
    
    logger.info(f"âœ… Media file deleted: {file_key}")
    return None


@router.get("/folders")
async def get_folders():
    """å–å¾—æ‰€æœ‰è³‡æ–™å¤¾åˆ—è¡¨åŠçµ±è¨ˆ"""
    
    async with db.pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT 
                folder,
                COUNT(*) as file_count,
                SUM(file_size) as total_size
            FROM media_files
            GROUP BY folder
            ORDER BY folder
            """
        )
    
    return [
        {
            'folder': row['folder'],
            'file_count': row['file_count'],
            'total_size': row['total_size']
        }
        for row in rows
    ]


@router.get("/stats")
async def get_media_stats():
    """å–å¾—åª’é«”çµ±è¨ˆè³‡è¨Š"""
    
    async with db.pool.acquire() as conn:
        stats = await conn.fetchrow(
            """
            SELECT 
                COUNT(*) as total_files,
                SUM(file_size) as total_size,
                COUNT(DISTINCT folder) as folder_count
            FROM media_files
            """
        )
    
    return dict(stats)


@router.post("/sync-from-r2")
async def sync_from_r2():
    """
    æƒæ R2 ä¸¦åŒ¯å…¥æ‰€æœ‰æª”æ¡ˆåˆ°è³‡æ–™åº«
    
    - æƒæ R2 bucket ä¸­çš„æ‰€æœ‰æª”æ¡ˆ
    - åŒ¯å…¥åˆ°è³‡æ–™åº«ï¼ˆå·²å­˜åœ¨çš„æœƒè·³éï¼‰
    - è¿”å›åŒ¯å…¥çµ±è¨ˆ
    """
    try:
        # åˆ—å‡º R2 æ‰€æœ‰æª”æ¡ˆ
        response = r2_storage.s3_client.list_objects_v2(
            Bucket=r2_storage.bucket_name
        )
        
        if 'Contents' not in response:
            return {
                "message": "R2 bucket æ˜¯ç©ºçš„",
                "imported": 0,
                "skipped": 0,
                "total": 0
            }
        
        total_files = len(response['Contents'])
        imported_count = 0
        skipped_count = 0
        
        async with db.pool.acquire() as conn:
            for obj in response['Contents']:
                file_key = obj['Key']
                file_size = obj['Size']
                last_modified = obj['LastModified']
                
                # è§£æè³‡æ–™å¤¾å’Œæª”å
                if '/' in file_key:
                    folder = '/'.join(file_key.split('/')[:-1])
                    filename = file_key.split('/')[-1]
                else:
                    folder = 'uploads'
                    filename = file_key
                
                # è·³éå·²å­˜åœ¨çš„æª”æ¡ˆ
                exists = await conn.fetchval(
                    "SELECT id FROM media_files WHERE file_key = $1",
                    file_key
                )
                
                if exists:
                    skipped_count += 1
                    continue
                
                # åµæ¸¬ MIME é¡å‹
                mime_type, _ = mimetypes.guess_type(filename)
                mime_type = mime_type or 'application/octet-stream'
                
                # ç”Ÿæˆå…¬é–‹ URL
                file_url = r2_storage.get_file_url(file_key)
                
                # å˜—è©¦ç²å–åœ–ç‰‡å°ºå¯¸
                width, height = None, None
                if mime_type.startswith('image/'):
                    try:
                        obj_data = r2_storage.s3_client.get_object(
                            Bucket=r2_storage.bucket_name,
                            Key=file_key
                        )
                        content = obj_data['Body'].read()
                        image = Image.open(io.BytesIO(content))
                        width, height = image.size
                    except:
                        pass
                
                # æ’å…¥è³‡æ–™åº«
                await conn.execute(
                    """
                    INSERT INTO media_files (
                        filename, original_filename, file_key, file_url,
                        file_size, mime_type, folder, uploaded_by, created_at,
                        width, height
                    )
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                    """,
                    filename,
                    filename,
                    file_key,
                    file_url,
                    file_size,
                    mime_type,
                    folder,
                    "synced",
                    last_modified.replace(tzinfo=None),
                    width,
                    height
                )
                
                imported_count += 1
        
        logger.info(f"âœ… R2 sync completed: {imported_count} imported, {skipped_count} skipped")
        
        return {
            "message": "åŒæ­¥å®Œæˆ",
            "imported": imported_count,
            "skipped": skipped_count,
            "total": total_files
        }
        
    except Exception as e:
        logger.error(f"âŒ R2 sync failed: {e}")
        raise HTTPException(status_code=500, detail=f"åŒæ­¥å¤±æ•—ï¼š{str(e)}")
